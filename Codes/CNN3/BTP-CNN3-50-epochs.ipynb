{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Agt1zntm7NSI"
      },
      "outputs": [],
      "source": [
        "# Tomato Leaf Disease Detection\n",
        "\n",
        "# In this program I will build 3 differnt CNN models to find maximum accuracy.\n",
        "# I will then build two transfer learning model approaches namely Incpetion-V3 and VGG-16\n",
        "\n",
        "# Then, I will do the testing with the model from which we obtain highest accuracy.\n",
        "\n",
        "# Code I: I have used one FC layer with batch size = default\n",
        "# CodeII: I have used two FC layer with batch size = default\n",
        "# Code III: I have used one FC layer with batch size = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QF4UJuKM7NSN"
      },
      "outputs": [],
      "source": [
        "# Importing Libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bExrfoFz7NSO",
        "outputId": "c4d79710-871f-49c9-c797-4b3f5ef5517f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Importing the images \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "qWAzeqUynv2u"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile('/content/drive/MyDrive/BTP/Dataset/tomato.zip','r') as zipObj:\n",
        "  zipObj.extractall('/content/drive/MyDrive/BTP/Dataset/dataset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ytOfCPALylp3"
      },
      "outputs": [],
      "source": [
        "TRAINING_DIR = '/content/drive/MyDrive/BTP/Dataset/dataset/New Plant Diseases Dataset(Augmented)/train/' \n",
        "TESTING_DIR = '/content/drive/MyDrive/BTP/Dataset/dataset/New Plant Diseases Dataset(Augmented)/valid/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CPTGgrv7NSP",
        "outputId": "b07eb69a-21b5-4aea-e07d-8d187dabfc32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 14678 images belonging to 10 classes.\n"
          ]
        }
      ],
      "source": [
        "#It provides a host of different augmentation techniques like standardization, rotation, \n",
        "#shifts, flips, brightness change, and many more\n",
        "train_datagen = ImageDataGenerator(\n",
        "        validation_split=0.2,\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        TRAINING_DIR,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical',\n",
        "        shuffle=True,\n",
        "        subset=\"training\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Y261dxjZP8pK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b20cf3af-5c5c-491a-b474-8c8279f61ef2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3667 images belonging to 10 classes.\n"
          ]
        }
      ],
      "source": [
        "validation_generator = train_datagen.flow_from_directory(\n",
        "        TRAINING_DIR,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical',\n",
        "        shuffle=True,\n",
        "        subset=\"validation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "d64DAiEd7NSP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e8912e2-a837-44f7-e96d-26260918a42f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4585 images belonging to 10 classes.\n"
          ]
        }
      ],
      "source": [
        "test_generator = test_datagen.flow_from_directory(\n",
        "        TESTING_DIR,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical',\n",
        "        shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "kxA1xsGYJGqT"
      },
      "outputs": [],
      "source": [
        "# train_X=train_generator\n",
        "# train_Y=train_generator.classes\n",
        "# test_X=test_generator\n",
        "# test_Y = test_generator.classes\n",
        "# print(\"Train_X or X_train\",train_X)\n",
        "# print(\"Train_Y or Y_train\",train_Y)\n",
        "# print(\"Test_X or X_test\",test_X)\n",
        "# print(\"Test_Y or Y_test\",test_Y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-GH3AEi2gbn"
      },
      "source": [
        "# Creating the first CNN model\n",
        "\n",
        "## 1. Using K-Fold Cross Valdation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "TKjOlLuKJDvy"
      },
      "outputs": [],
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "# # fix random seed for reproducibility\n",
        "# seed = 7\n",
        "# # split into 67% for train and 33% for test\n",
        "# X_train, X_test, y_train, y_test = train_test_split(train_generator, test_generator, test_size=0.33)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "h6TfSRECxqib"
      },
      "outputs": [],
      "source": [
        "# X_train=train_X\n",
        "# Y_train=train_Y\n",
        "\n",
        "X_train, Y_train = next(train_generator)\n",
        "X_test, Y_test = next(validation_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4eWcDSlJjh8"
      },
      "outputs": [],
      "source": [
        "# print(\"X_Train\",X_train)\n",
        "# print(\"Y_Train\",Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0aC7QBfAw97q"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import (\n",
        "    Dense,\n",
        "    Dropout,\n",
        "    MaxPooling2D,\n",
        "    Conv2D,\n",
        "    Flatten,\n",
        "    BatchNormalization,\n",
        ")\n",
        "\n",
        "\n",
        "cvscores = []\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=5)\n",
        "\n",
        "for train, val in kfold.split(X_train, Y_train):\n",
        "    model = tf.keras.models.Sequential()\n",
        "\n",
        "    #Convolution layer 1\n",
        "    model.add(tf.keras.layers.Conv2D(filters=32,kernel_size = 3, activation='relu',input_shape=[150, 150,3]))\n",
        "    # cnn.add(BatchNormalization())\n",
        "\n",
        "    # Pooling 1\n",
        "    model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "    # cnn.add(BatchNormalization())\n",
        "\n",
        "    #Convolution layer 2\n",
        "    model.add(tf.keras.layers.Conv2D(filters=32,kernel_size = 3, activation='relu',input_shape=[150, 150,3]))\n",
        "    # cnn.add(Dropout(0.25))\n",
        "\n",
        "    # cnn.add(BatchNormalization())\n",
        "\n",
        "    # Pooling 2\n",
        "    model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "    # cnn.add(BatchNormalization())\n",
        "\n",
        "    # Flattening\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    # cnn.add(BatchNormalization())\n",
        "\n",
        "    #Full Connection\n",
        "    model.add(tf.keras.layers.Dense(units=128,activation='relu'))\n",
        "    # cnn.add(BatchNormalization())\n",
        "\n",
        "    #Output Layer\n",
        "    model.add(tf.keras.layers.Dense(units=10,activation='softmax'))\n",
        "\n",
        "    #Compiling\n",
        "    model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "    # # Summary of the model\n",
        "    # model.summary()\n",
        "\n",
        "    # temp = model.fit(X_train[train], Y_train[train],epochs=50)\n",
        "\n",
        "    temp = model.fit(\n",
        "        X_train[train], Y_train[train], batch_size=32, epochs=30, verbose=1\n",
        "    )\n",
        "\n",
        "    scores = model.evaluate(X_train[val], Y_train[val])\n",
        "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1] * 100))\n",
        "    cvscores.append(scores[1] * 100)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1URDV2Z31ouA"
      },
      "outputs": [],
      "source": [
        "print(cvscores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPEEI7AD1rRa"
      },
      "outputs": [],
      "source": [
        "plt.plot(cvscores)\n",
        "plt.xlabel(\"k-fold\")\n",
        "plt.ylabel(\"val accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n24sJM8o3UTA"
      },
      "outputs": [],
      "source": [
        "# Scores is just a list containing loss and accuracy value\n",
        "scores=model.evaluate(train_generator)\n",
        "scores2=model.evaluate(test_generator)\n",
        "print(\"Training Loss is : \"+str(scores[0]))\n",
        "print(\"Training Accuracy is : \"+str(scores[1]*100)+\" %\")\n",
        "print(\"Testing Loss is : \"+str(scores2[0]))\n",
        "print(\"Testing Accuracy is : \"+str(scores2[1]*100)+\" %\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGiWL2qL2BVW"
      },
      "outputs": [],
      "source": [
        "print(\"Mean of the accuracies: \", np.mean(cvscores))\n",
        "print(\"Standard devaiation of the accuracies: \", np.std(cvscores))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-g8O1QT72E0Z"
      },
      "outputs": [],
      "source": [
        "plt.plot(temp.history[\"accuracy\"])\n",
        "plt.plot(temp.history[\"loss\"])\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.legend([\"accuracy\", \"loss\"])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ha77vdGb7NSQ"
      },
      "source": [
        "# Creating the first CNN model\n",
        "## 2. Using Hold-out method\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zX3Tw0XF7NSS"
      },
      "outputs": [],
      "source": [
        "# First model\n",
        "\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Dropout\n",
        "\n",
        "cnn = tf.keras.models.Sequential()\n",
        "\n",
        "#Convolution layer 1\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size = 3, activation='relu',input_shape=[150, 150,3]))\n",
        "# cnn.add(BatchNormalization())\n",
        "\n",
        "# Pooling 1\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "# cnn.add(BatchNormalization())\n",
        "\n",
        "#Convolution layer 2\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size = 3, activation='relu',input_shape=[150, 150,3]))\n",
        "# cnn.add(Dropout(0.25))\n",
        "\n",
        "# cnn.add(BatchNormalization())\n",
        "\n",
        "# Pooling 2\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "# cnn.add(BatchNormalization())\n",
        "\n",
        "# Flattening\n",
        "cnn.add(tf.keras.layers.Flatten())\n",
        "# cnn.add(BatchNormalization())\n",
        "\n",
        "#Full Connection\n",
        "cnn.add(tf.keras.layers.Dense(units=128,activation='relu'))\n",
        "# cnn.add(BatchNormalization())\n",
        "\n",
        "#Output Layer\n",
        "cnn.add(tf.keras.layers.Dense(units=10,activation='softmax'))\n",
        "\n",
        "#Compiling\n",
        "cnn.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "# Summary of the model\n",
        "cnn.summary()\n",
        "\n",
        "# Fit\n",
        "\n",
        "# temp = cnn.fit(x = train_generator, validation_data=test_generator,epochs=5)\n",
        "temp = cnn.fit(x = train_generator, validation_data=validation_generator,epochs=50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATtNkChNYCNh"
      },
      "outputs": [],
      "source": [
        "# plot the model accuracy and validation accuracy\n",
        "\n",
        "plt.plot(temp.history['accuracy'])\n",
        "plt.plot(temp.history['val_accuracy'])\n",
        "plt.legend(['accuracy','validation accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5Tcje1QFP6h"
      },
      "outputs": [],
      "source": [
        "# Scores is just a list containing loss and accuracy value\n",
        "scores=cnn.evaluate(train_generator)\n",
        "scores2=cnn.evaluate(test_generator)\n",
        "print(\"Training Loss is : \"+str(scores[0]))\n",
        "print(\"Training Accuracy is : \"+str(scores[1]*100)+\" %\")\n",
        "print(\"Testing Loss is : \"+str(scores2[0]))\n",
        "print(\"Testing Accuracy is : \"+str(scores2[1]*100)+\" %\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DEvMRQASX4x-"
      },
      "outputs": [],
      "source": [
        "test_steps_per_epoch = np.math.ceil(test_generator.samples / test_generator.batch_size)\n",
        "predictions = cnn.predict(test_generator, steps=test_steps_per_epoch)\n",
        "\n",
        "# Get most likely class\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Get true classes and class Labels\n",
        "true_classes = test_generator.classes\n",
        "class_labels = list(test_generator.class_indices.keys())   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHzcODZ2bApr"
      },
      "source": [
        "## Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IvJFqG9DX-9x"
      },
      "outputs": [],
      "source": [
        "import sklearn.metrics as metrics\n",
        "report = metrics.classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
        "print(report) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3ol20wRbFij"
      },
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8yTtgmIYT-V"
      },
      "outputs": [],
      "source": [
        "#Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "sns.heatmap(confusion_matrix(true_classes,predicted_classes),annot=True,fmt='.5g') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZrzKqwL7NSV"
      },
      "outputs": [],
      "source": [
        "# Testing the model\n",
        "# from keras.preprocessing import image\n",
        "\n",
        "import keras.utils as image\n",
        "\n",
        "test = image.load_img(\"/content/drive/MyDrive/BTP/Dataset/dataset/New Plant Diseases Dataset(Augmented)/valid/Tomato___Spider_mites Two-spotted_spider_mite/00fa99e8-2605-4d72-be69-98277587d84b___Com.G_SpM_FL 1453_flipTB.JPG\",target_size = (150, 150))\n",
        "test=image.img_to_array(test)\n",
        "# /content/drive/MyDrive/BTP/Dataset/dataset/New Plant Diseases Dataset(Augmented)/valid/Tomato___Spider_mites Two-spotted_spider_mite/00fa99e8-2605-4d72-be69-98277587d84b___Com.G_SpM_FL 1453_flipTB.JPG\n",
        "test=np.expand_dims(test,axis=0)\n",
        "result=cnn.predict(test)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9ud3a6Q7NSU"
      },
      "outputs": [],
      "source": [
        "# plot the loss\n",
        "plt.plot(temp.history['loss'], label='train loss')\n",
        "plt.plot(temp.history['val_loss'], label='val loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('LossVal_loss')\n",
        "\n",
        "# plot the accuracy\n",
        "plt.plot(temp.history['accuracy'], label='train acc')\n",
        "plt.plot(temp.history['val_accuracy'], label='val acc')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('AccVal_acc')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fnLB2h9a7NSW"
      },
      "outputs": [],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmWWvFwRoP5y"
      },
      "source": [
        "## CNN Model-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "cYclMOga7NSX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 900
        },
        "outputId": "f7047d44-41df-4337-c744-83365c805443"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 72, 72, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 36, 36, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 41472)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               5308544   \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 128)              512       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,337,002\n",
            "Trainable params: 5,336,746\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "  4/112 [>.............................] - ETA: 14:03 - loss: 0.6637 - accuracy: 0.3203"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-29208b017ca2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m#temp = cnn2.fit(x = train_generator, validation_data=test_generator,epochs=25)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Second model\n",
        "\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Dropout\n",
        "\n",
        "cnn2 = tf.keras.models.Sequential()\n",
        "\n",
        "#Convolution layer 1\n",
        "cnn2.add(tf.keras.layers.Conv2D(filters=32,kernel_size = 3, activation='relu',input_shape=[150, 150,3]))\n",
        "# cnn2.add(BatchNormalization())\n",
        "\n",
        "# Pooling 1\n",
        "cnn2.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "# cnn2.add(BatchNormalization())\n",
        "\n",
        "#Convolution layer 2\n",
        "cnn2.add(tf.keras.layers.Conv2D(filters=32,kernel_size = 3, activation='relu',input_shape=[150, 150,3]))\n",
        "# cnn2.add(BatchNormalization())\n",
        "\n",
        "# Pooling 2\n",
        "cnn2.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "#cnn2.add(Dropout(0.25))\n",
        "# cnn2.add(BatchNormalization())\n",
        "\n",
        "# Flattening\n",
        "cnn2.add(tf.keras.layers.Flatten())\n",
        "\n",
        "#Full Conncetion\n",
        "cnn2.add(tf.keras.layers.Dense(units=128,activation='relu'))\n",
        "cnn2.add(BatchNormalization())\n",
        "\n",
        "#Full Conncetion\n",
        "cnn2.add(tf.keras.layers.Dense(units=128,activation='relu'))\n",
        "# cnn2.add(BatchNormalization())\n",
        "\n",
        "#Output Layer\n",
        "cnn2.add(tf.keras.layers.Dense(units=10,activation='softmax'))\n",
        "\n",
        "#Compiling\n",
        "cnn2.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "# Summary of the model\n",
        "cnn2.summary()\n",
        "\n",
        "# Fit\n",
        "#temp = cnn2.fit(x = train_generator, validation_data=test_generator,epochs=25)\n",
        "temp = cnn2.fit(x = train_generator, validation_data=validation_generator,epochs=50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1Oj49WwnsuG"
      },
      "outputs": [],
      "source": [
        "# Scores is just a list containing loss and accuracy value\n",
        "scores=cnn2.evaluate(train_generator)\n",
        "scores2=cnn2.evaluate(test_generator)\n",
        "print(\"Training Loss is :\"+str(scores[0]))\n",
        "print(\"Training Accuracy is :\"+str(scores[1]*100)+\" %\")\n",
        "print(\"Testing Loss is : \"+str(scores2[0]))\n",
        "print(\"Testing Accuracy is : \"+str(scores2[1]*100)+\" %\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlX5p_HYn2iU"
      },
      "outputs": [],
      "source": [
        "test_steps_per_epoch = np.math.ceil(test_generator.samples / test_generator.batch_size)\n",
        "predictions = cnn2.predict(test_generator, steps=test_steps_per_epoch)\n",
        "\n",
        "# Get most likely class\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Get true classes and class Labels\n",
        "true_classes = test_generator.classes\n",
        "class_labels = list(test_generator.class_indices.keys())   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSmaloEbn7jL"
      },
      "outputs": [],
      "source": [
        "#Classification Report\n",
        "import sklearn.metrics as metrics\n",
        "report = metrics.classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
        "print(report) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epRFfRNqoBsw"
      },
      "outputs": [],
      "source": [
        "#Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "sns.heatmap(confusion_matrix(true_classes,predicted_classes),annot=True,fmt='.5g') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EX4UvOcU7NSX"
      },
      "outputs": [],
      "source": [
        "# plot the loss\n",
        "plt.plot(temp.history['loss'], label='train loss')\n",
        "plt.plot(temp.history['val_loss'], label='val loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('LossVal_loss')\n",
        "\n",
        "# plot the accuracy\n",
        "plt.plot(temp.history['accuracy'], label='train acc')\n",
        "plt.plot(temp.history['val_accuracy'], label='val acc')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('AccVal_acc')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-5UMyq2n-XK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTyILRi8oZ6l"
      },
      "source": [
        "## CNN Model-3 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "dRg6C7yG7NSY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6b9d31d-107f-4f95-a918-526128ebc5fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 74, 74, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 72, 72, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 36, 36, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 41472)             0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 128)               5308544   \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,319,978\n",
            "Trainable params: 5,319,978\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "459/459 [==============================] - 143s 311ms/step - loss: 0.1830 - accuracy: 0.6236 - val_loss: 0.1385 - val_accuracy: 0.7101\n",
            "Epoch 2/50\n",
            "459/459 [==============================] - 139s 303ms/step - loss: 0.1058 - accuracy: 0.8104 - val_loss: 0.1188 - val_accuracy: 0.7780\n",
            "Epoch 3/50\n",
            "459/459 [==============================] - 141s 307ms/step - loss: 0.0839 - accuracy: 0.8529 - val_loss: 0.0865 - val_accuracy: 0.8555\n",
            "Epoch 4/50\n",
            "459/459 [==============================] - 145s 315ms/step - loss: 0.0688 - accuracy: 0.8854 - val_loss: 0.0750 - val_accuracy: 0.8806\n",
            "Epoch 5/50\n",
            "459/459 [==============================] - 148s 323ms/step - loss: 0.0602 - accuracy: 0.9007 - val_loss: 0.0737 - val_accuracy: 0.8808\n",
            "Epoch 6/50\n",
            "459/459 [==============================] - 138s 301ms/step - loss: 0.0545 - accuracy: 0.9124 - val_loss: 0.0686 - val_accuracy: 0.8803\n",
            "Epoch 7/50\n",
            "459/459 [==============================] - 136s 297ms/step - loss: 0.0477 - accuracy: 0.9236 - val_loss: 0.0638 - val_accuracy: 0.8975\n",
            "Epoch 8/50\n",
            "459/459 [==============================] - 139s 303ms/step - loss: 0.0444 - accuracy: 0.9314 - val_loss: 0.0665 - val_accuracy: 0.8882\n",
            "Epoch 9/50\n",
            "459/459 [==============================] - 137s 300ms/step - loss: 0.0404 - accuracy: 0.9377 - val_loss: 0.0517 - val_accuracy: 0.9182\n",
            "Epoch 10/50\n",
            "459/459 [==============================] - 140s 305ms/step - loss: 0.0352 - accuracy: 0.9477 - val_loss: 0.0571 - val_accuracy: 0.9122\n",
            "Epoch 11/50\n",
            "459/459 [==============================] - 144s 314ms/step - loss: 0.0357 - accuracy: 0.9474 - val_loss: 0.0609 - val_accuracy: 0.9005\n",
            "Epoch 12/50\n",
            "459/459 [==============================] - 147s 320ms/step - loss: 0.0319 - accuracy: 0.9541 - val_loss: 0.0565 - val_accuracy: 0.9084\n",
            "Epoch 13/50\n",
            "459/459 [==============================] - 138s 302ms/step - loss: 0.0281 - accuracy: 0.9604 - val_loss: 0.0719 - val_accuracy: 0.8915\n",
            "Epoch 14/50\n",
            "459/459 [==============================] - 141s 307ms/step - loss: 0.0283 - accuracy: 0.9604 - val_loss: 0.0478 - val_accuracy: 0.9269\n",
            "Epoch 15/50\n",
            "459/459 [==============================] - 142s 310ms/step - loss: 0.0262 - accuracy: 0.9616 - val_loss: 0.0546 - val_accuracy: 0.9176\n",
            "Epoch 16/50\n",
            "459/459 [==============================] - 142s 309ms/step - loss: 0.0238 - accuracy: 0.9677 - val_loss: 0.0490 - val_accuracy: 0.9239\n",
            "Epoch 17/50\n",
            "459/459 [==============================] - 139s 302ms/step - loss: 0.0233 - accuracy: 0.9685 - val_loss: 0.0617 - val_accuracy: 0.9073\n",
            "Epoch 18/50\n",
            "459/459 [==============================] - 137s 299ms/step - loss: 0.0226 - accuracy: 0.9689 - val_loss: 0.0458 - val_accuracy: 0.9250\n",
            "Epoch 19/50\n",
            "459/459 [==============================] - 138s 300ms/step - loss: 0.0201 - accuracy: 0.9731 - val_loss: 0.0646 - val_accuracy: 0.9056\n",
            "Epoch 20/50\n",
            "459/459 [==============================] - 143s 312ms/step - loss: 0.0192 - accuracy: 0.9757 - val_loss: 0.0537 - val_accuracy: 0.9280\n",
            "Epoch 21/50\n",
            "459/459 [==============================] - 137s 299ms/step - loss: 0.0182 - accuracy: 0.9772 - val_loss: 0.0569 - val_accuracy: 0.9236\n",
            "Epoch 22/50\n",
            "459/459 [==============================] - 136s 297ms/step - loss: 0.0188 - accuracy: 0.9758 - val_loss: 0.0609 - val_accuracy: 0.9179\n",
            "Epoch 23/50\n",
            "459/459 [==============================] - 141s 307ms/step - loss: 0.0182 - accuracy: 0.9771 - val_loss: 0.0577 - val_accuracy: 0.9266\n",
            "Epoch 24/50\n",
            "459/459 [==============================] - 146s 319ms/step - loss: 0.0166 - accuracy: 0.9784 - val_loss: 0.0585 - val_accuracy: 0.9166\n",
            "Epoch 25/50\n",
            "459/459 [==============================] - 144s 315ms/step - loss: 0.0151 - accuracy: 0.9807 - val_loss: 0.0546 - val_accuracy: 0.9305\n",
            "Epoch 26/50\n",
            "459/459 [==============================] - 138s 301ms/step - loss: 0.0190 - accuracy: 0.9770 - val_loss: 0.0606 - val_accuracy: 0.9144\n",
            "Epoch 27/50\n",
            "459/459 [==============================] - 139s 303ms/step - loss: 0.0126 - accuracy: 0.9851 - val_loss: 0.0530 - val_accuracy: 0.9329\n",
            "Epoch 28/50\n",
            "459/459 [==============================] - 143s 313ms/step - loss: 0.0133 - accuracy: 0.9846 - val_loss: 0.0551 - val_accuracy: 0.9359\n",
            "Epoch 29/50\n",
            "459/459 [==============================] - 144s 313ms/step - loss: 0.0156 - accuracy: 0.9811 - val_loss: 0.0621 - val_accuracy: 0.9277\n",
            "Epoch 30/50\n",
            "459/459 [==============================] - 140s 306ms/step - loss: 0.0133 - accuracy: 0.9845 - val_loss: 0.0544 - val_accuracy: 0.9305\n",
            "Epoch 31/50\n",
            "459/459 [==============================] - 144s 313ms/step - loss: 0.0120 - accuracy: 0.9862 - val_loss: 0.0613 - val_accuracy: 0.9146\n",
            "Epoch 32/50\n",
            "459/459 [==============================] - 141s 308ms/step - loss: 0.0129 - accuracy: 0.9847 - val_loss: 0.0637 - val_accuracy: 0.9245\n",
            "Epoch 33/50\n",
            "459/459 [==============================] - 138s 300ms/step - loss: 0.0129 - accuracy: 0.9849 - val_loss: 0.0584 - val_accuracy: 0.9239\n",
            "Epoch 34/50\n",
            "459/459 [==============================] - 141s 306ms/step - loss: 0.0099 - accuracy: 0.9892 - val_loss: 0.0758 - val_accuracy: 0.9130\n",
            "Epoch 35/50\n",
            "459/459 [==============================] - 137s 298ms/step - loss: 0.0129 - accuracy: 0.9854 - val_loss: 0.0658 - val_accuracy: 0.9201\n",
            "Epoch 36/50\n",
            "459/459 [==============================] - 139s 304ms/step - loss: 0.0115 - accuracy: 0.9866 - val_loss: 0.0536 - val_accuracy: 0.9343\n",
            "Epoch 37/50\n",
            "459/459 [==============================] - 139s 302ms/step - loss: 0.0106 - accuracy: 0.9870 - val_loss: 0.0513 - val_accuracy: 0.9376\n",
            "Epoch 38/50\n",
            "459/459 [==============================] - 142s 310ms/step - loss: 0.0098 - accuracy: 0.9901 - val_loss: 0.0533 - val_accuracy: 0.9384\n",
            "Epoch 39/50\n",
            "459/459 [==============================] - 142s 309ms/step - loss: 0.0121 - accuracy: 0.9861 - val_loss: 0.0538 - val_accuracy: 0.9359\n",
            "Epoch 40/50\n",
            "459/459 [==============================] - 143s 311ms/step - loss: 0.0097 - accuracy: 0.9894 - val_loss: 0.0634 - val_accuracy: 0.9326\n",
            "Epoch 41/50\n",
            "459/459 [==============================] - 136s 296ms/step - loss: 0.0085 - accuracy: 0.9912 - val_loss: 0.0657 - val_accuracy: 0.9307\n",
            "Epoch 42/50\n",
            "459/459 [==============================] - 147s 320ms/step - loss: 0.0092 - accuracy: 0.9905 - val_loss: 0.0605 - val_accuracy: 0.9354\n",
            "Epoch 43/50\n",
            "459/459 [==============================] - 138s 300ms/step - loss: 0.0097 - accuracy: 0.9894 - val_loss: 0.0737 - val_accuracy: 0.9171\n",
            "Epoch 44/50\n",
            "459/459 [==============================] - 137s 299ms/step - loss: 0.0095 - accuracy: 0.9898 - val_loss: 0.0484 - val_accuracy: 0.9416\n",
            "Epoch 45/50\n",
            "459/459 [==============================] - 161s 351ms/step - loss: 0.0091 - accuracy: 0.9903 - val_loss: 0.0660 - val_accuracy: 0.9223\n",
            "Epoch 46/50\n",
            "459/459 [==============================] - 136s 296ms/step - loss: 0.0086 - accuracy: 0.9916 - val_loss: 0.0740 - val_accuracy: 0.9201\n",
            "Epoch 47/50\n",
            "459/459 [==============================] - 135s 295ms/step - loss: 0.0083 - accuracy: 0.9913 - val_loss: 0.0548 - val_accuracy: 0.9389\n",
            "Epoch 48/50\n",
            "459/459 [==============================] - 140s 305ms/step - loss: 0.0081 - accuracy: 0.9913 - val_loss: 0.0542 - val_accuracy: 0.9356\n",
            "Epoch 49/50\n",
            "459/459 [==============================] - 143s 311ms/step - loss: 0.0114 - accuracy: 0.9886 - val_loss: 0.0680 - val_accuracy: 0.9201\n",
            "Epoch 50/50\n",
            "459/459 [==============================] - 142s 310ms/step - loss: 0.0068 - accuracy: 0.9929 - val_loss: 0.0524 - val_accuracy: 0.9389\n"
          ]
        }
      ],
      "source": [
        "# Third model\n",
        "\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Dropout\n",
        "\n",
        "cnn3 = tf.keras.models.Sequential()\n",
        "\n",
        "#Convolution layer 1\n",
        "cnn3.add(tf.keras.layers.Conv2D(filters=32,kernel_size = 3, activation='relu',input_shape=[150, 150,3]))\n",
        "# cnn3.add(BatchNormalization())\n",
        "\n",
        "# Pooling 1\n",
        "cnn3.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "# cnn3.add(BatchNormalization())\n",
        "\n",
        "#Convolution layer 2\n",
        "cnn3.add(tf.keras.layers.Conv2D(filters=32,kernel_size = 3, activation='relu',input_shape=[150, 150,3]))\n",
        "# cnn3.add(BatchNormalization())\n",
        "\n",
        "# Pooling 2\n",
        "cnn3.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "# cnn3.add(BatchNormalization())\n",
        "\n",
        "# Flattening\n",
        "cnn3.add(tf.keras.layers.Flatten())\n",
        "# cnn3.add(BatchNormalization())\n",
        "\n",
        "#Full Conncetion\n",
        "cnn3.add(tf.keras.layers.Dense(units=128,activation='relu'))\n",
        "# cnn3.add(Dropout(0.25))\n",
        "\n",
        "#Output Layer\n",
        "cnn3.add(tf.keras.layers.Dense(units=10,activation='softmax'))\n",
        "\n",
        "#Compiling\n",
        "cnn3.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "# Summary of the model\n",
        "cnn3.summary()\n",
        "\n",
        "# Fit\n",
        "#temp = cnn3.fit(x = train_generator, validation_data=test_generator,epochs=25,batch_size = 64)\n",
        "temp = cnn3.fit(x = train_generator, validation_data=validation_generator,epochs=50,batch_size = 64)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "WHrLyCgNo28T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "554b9c34-9eaa-4846-8f4f-785e946806c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "459/459 [==============================] - 108s 235ms/step - loss: 0.0059 - accuracy: 0.9936\n",
            "144/144 [==============================] - 14s 97ms/step - loss: 0.0860 - accuracy: 0.9178\n",
            "Training Loss is :0.005929809994995594\n",
            "Training Accuracy is :99.3595838546753 %\n",
            "Testing Loss is : 0.08598877489566803\n",
            "Testing Accuracy is : 91.77753329277039 %\n"
          ]
        }
      ],
      "source": [
        "# Scores is just a list containing loss and accuracy value\n",
        "scores=cnn3.evaluate(train_generator)\n",
        "scores2=cnn3.evaluate(test_generator)\n",
        "print(\"Training Loss is :\"+str(scores[0]))\n",
        "print(\"Training Accuracy is :\"+str(scores[1]*100)+\" %\")\n",
        "print(\"Testing Loss is : \"+str(scores2[0]))\n",
        "print(\"Testing Accuracy is : \"+str(scores2[1]*100)+\" %\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UxJNONco48K"
      },
      "outputs": [],
      "source": [
        "test_steps_per_epoch = np.math.ceil(test_generator.samples / test_generator.batch_size)\n",
        "predictions = cnn3.predict(test_generator, steps=test_steps_per_epoch)\n",
        "\n",
        "# Get most likely class\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Get true classes and class Labels\n",
        "true_classes = test_generator.classes\n",
        "class_labels = list(test_generator.class_indices.keys())   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "NabyKcUeo6b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad047b56-b29e-47e1-fd16-1093518ae4fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               precision    recall  f1-score   support\n",
            "\n",
            "                      Tomato___Bacterial_spot       0.07      0.07      0.07       425\n",
            "                        Tomato___Early_blight       0.12      0.14      0.13       480\n",
            "                         Tomato___Late_blight       0.06      0.06      0.06       463\n",
            "                           Tomato___Leaf_Mold       0.11      0.09      0.10       470\n",
            "                  Tomato___Septoria_leaf_spot       0.07      0.08      0.07       436\n",
            "Tomato___Spider_mites Two-spotted_spider_mite       0.12      0.10      0.11       435\n",
            "                         Tomato___Target_Spot       0.10      0.10      0.10       457\n",
            "       Tomato___Tomato_Yellow_Leaf_Curl_Virus       0.11      0.11      0.11       490\n",
            "                 Tomato___Tomato_mosaic_virus       0.09      0.10      0.10       448\n",
            "                             Tomato___healthy       0.14      0.15      0.14       481\n",
            "\n",
            "                                     accuracy                           0.10      4585\n",
            "                                    macro avg       0.10      0.10      0.10      4585\n",
            "                                 weighted avg       0.10      0.10      0.10      4585\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Classification Report\n",
        "import sklearn.metrics as metrics\n",
        "report = metrics.classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
        "print(report) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zfn3dlUQo8c_"
      },
      "outputs": [],
      "source": [
        "#Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "sns.heatmap(confusion_matrix(true_classes,predicted_classes),annot=True,fmt='.5g') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "g3qXXAkn7NSY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "8b5d0ed9-6855-4f07-f254-7272cceae640"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# plot the loss\n",
        "plt.plot(temp.history['loss'], label='train loss')\n",
        "plt.plot(temp.history['val_loss'], label='val loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('LossVal_loss')\n",
        "\n",
        "# plot the accuracy\n",
        "plt.plot(temp.history['accuracy'], label='train acc')\n",
        "plt.plot(temp.history['val_accuracy'], label='val acc')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('AccVal_acc')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0KbT9jWoucE"
      },
      "source": [
        "## Inception-V3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a46vCVPMaEya"
      },
      "source": [
        "## Detection of Tomato Leaf Disease by Transfer learning InceptionV3\n",
        "\n",
        "#### Importing libraries and essentials for the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "8F9_Wwr2Zm29"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras \n",
        "from tensorflow.keras.layers import Dense , Flatten\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZUVoMgZaIpV"
      },
      "source": [
        "##### Data Augmentation\n",
        "\n",
        "Increasing the data by horizontal flip, shear range and rotation range to get the image classification better accuracy.\n",
        "Data augmentation is a strategy that enables practitioners to significantly increase the diversity of data available for training models, without actually collecting new data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "NNq1TuABaY9i"
      },
      "outputs": [],
      "source": [
        "train_datagen=ImageDataGenerator(validation_split=0.2,rescale=1./255,\n",
        "                                 horizontal_flip=True,rotation_range=.2,shear_range=.2)\n",
        "test_datagen=ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b92n98soai-0"
      },
      "source": [
        "##### About Dataset\n",
        "\n",
        "   1. The dataset consists of training data, and validation data.\n",
        "   2. The training data consists of 18345  images with 10 classes and 3,875 test images with 10.\n",
        "   3. The classes are Tomato___Bacterial_spot, Tomato___Early_blight, Tomato___healthy, Tomato___Late_blight, Tomato___Leaf_Mold, Tomato___Septoria_leaf_spot, Tomato___Spider_mites Two-spotted_spider_mite, Tomato___Target_Spot, Tomato___Tomato_mosaic_virus, Tomato___Tomato_Yellow_Leaf_Curl_Virus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "sTw5a39F2kks"
      },
      "outputs": [],
      "source": [
        "TRAINING_DIR = '/content/drive/MyDrive/BTP/Dataset/dataset/New Plant Diseases Dataset(Augmented)/train/' \n",
        "TESTING_DIR = '/content/drive/MyDrive/BTP/Dataset/dataset/New Plant Diseases Dataset(Augmented)/valid/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "96pNsIdqahzL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dc198e8-a95a-4119-863f-4df1ceab067e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 14678 images belonging to 10 classes.\n",
            "Found 3667 images belonging to 10 classes.\n",
            "Found 4585 images belonging to 10 classes.\n"
          ]
        }
      ],
      "source": [
        "training_set=train_datagen.flow_from_directory(TRAINING_DIR,\n",
        "                                               target_size=(224,224),class_mode=\"categorical\",batch_size=32,shuffle=True,subset=\"training\")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "        TRAINING_DIR,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical',\n",
        "        shuffle=True,\n",
        "        subset=\"validation\")\n",
        "\n",
        "test_set=test_datagen.flow_from_directory(TESTING_DIR,\n",
        "                                          target_size=(224,224),class_mode=\"categorical\",batch_size=32,shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzqJLAEzbtz1"
      },
      "source": [
        "### InceptionV3\n",
        "\n",
        "Inception v3 is a convolutional neural network for assisting in image analysis and object detection, and got its start as a module for Googlenet. It is the third edition of Google's Inception Convolutional Neural Network, originally introduced during the ImageNet Recognition Challenge. Just as ImageNet can be thought of as a database of classified visual objects, Inception helps classification of objects in the world of computer vision.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "5Ifa_GFFbyVd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a97f77f-3e3a-46dc-d2f0-6d4e28dfb8e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 4s 0us/step\n"
          ]
        }
      ],
      "source": [
        "inception=InceptionV3(input_shape=[224,224,3],weights=\"imagenet\",include_top=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwOhK3Ddb6BC"
      },
      "source": [
        "**We will not train the layers because the layers of InceptionV3 layers are already trained with imagenet dataset.** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "0ah8TVZ_b1qu"
      },
      "outputs": [],
      "source": [
        "for layer in inception.layers:\n",
        "  layer.trainable=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "NgHr0kyOb9uV"
      },
      "outputs": [],
      "source": [
        "folder=glob(\"/content/drive/MyDrive/BTP/Dataset/dataset/New Plant Diseases Dataset(Augmented)/train/*\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YxVbQzscH3F"
      },
      "source": [
        "**Adding a flatten layer along with a Dense layer whose neuron will be equal to the number of classes with and activation funtion softmax**\n",
        "\n",
        "**Then we will concat the model and name inception_model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "v63mx2KHcJG_"
      },
      "outputs": [],
      "source": [
        "x=Flatten()(inception.output)\n",
        "predict_inception=Dense(units=len(folder),activation=\"softmax\")(x)\n",
        "inception_model=Model(inputs=inception.input,outputs=predict_inception)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fc5kq2EcOPO"
      },
      "source": [
        "**We have taken the optimizer Adam and the loss will be categorical crossentropy and our aim will be to find the accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "c9g93COAcKsk"
      },
      "outputs": [],
      "source": [
        "inception_model.compile(optimizer=\"adam\",\n",
        "                        loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dW-M984ocR6B"
      },
      "source": [
        "#### Final Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "6MprrSEIcT3t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ecb5ae2-ba20-4ca3-e33b-8fd71e180623"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 111, 111, 32  864         ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 111, 111, 32  96         ['conv2d_6[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 111, 111, 32  0           ['batch_normalization_1[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 109, 109, 32  9216        ['activation[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 109, 109, 32  96         ['conv2d_7[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 109, 109, 32  0           ['batch_normalization_2[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 109, 109, 64  18432       ['activation_1[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 109, 109, 64  192        ['conv2d_8[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 109, 109, 64  0           ['batch_normalization_3[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_6 (MaxPooling2D)  (None, 54, 54, 64)  0           ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 54, 54, 80)   5120        ['max_pooling2d_6[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 54, 54, 80)  240         ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 54, 54, 80)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 52, 52, 192)  138240      ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 52, 52, 192)  576        ['conv2d_10[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 52, 52, 192)  0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_7 (MaxPooling2D)  (None, 25, 25, 192)  0          ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 25, 25, 64)   12288       ['max_pooling2d_7[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 25, 25, 64)  192         ['conv2d_14[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 25, 25, 64)   0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 25, 25, 48)   9216        ['max_pooling2d_7[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 25, 25, 96)   55296       ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 25, 25, 48)  144         ['conv2d_12[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 25, 25, 96)  288         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 25, 25, 48)   0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 25, 25, 96)   0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 25, 25, 192)  0          ['max_pooling2d_7[0][0]']        \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 25, 25, 64)   12288       ['max_pooling2d_7[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 25, 25, 64)   76800       ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 25, 25, 96)   82944       ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 25, 25, 32)   6144        ['average_pooling2d[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 25, 25, 64)  192         ['conv2d_11[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 25, 25, 64)  192         ['conv2d_13[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 25, 25, 96)  288         ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 25, 25, 32)  96          ['conv2d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 25, 25, 64)   0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 25, 25, 64)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 25, 25, 32)   0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " mixed0 (Concatenate)           (None, 25, 25, 256)  0           ['activation_5[0][0]',           \n",
            "                                                                  'activation_7[0][0]',           \n",
            "                                                                  'activation_10[0][0]',          \n",
            "                                                                  'activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 25, 25, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 25, 25, 64)  192         ['conv2d_21[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 25, 25, 48)   12288       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 25, 25, 96)   55296       ['activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 25, 25, 48)  144         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 25, 25, 96)  288         ['conv2d_22[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 25, 25, 48)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_1 (AveragePo  (None, 25, 25, 256)  0          ['mixed0[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 25, 25, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 25, 25, 64)   76800       ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 25, 25, 96)   82944       ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 25, 25, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 25, 25, 64)  192         ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 25, 25, 64)  192         ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 25, 25, 96)  288         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 25, 25, 64)  192         ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " mixed1 (Concatenate)           (None, 25, 25, 288)  0           ['activation_12[0][0]',          \n",
            "                                                                  'activation_14[0][0]',          \n",
            "                                                                  'activation_17[0][0]',          \n",
            "                                                                  'activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 25, 25, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 25, 25, 64)  192         ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 25, 25, 48)   13824       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 25, 25, 96)   55296       ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 25, 25, 48)  144         ['conv2d_26[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 25, 25, 96)  288         ['conv2d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 25, 25, 48)   0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_2 (AveragePo  (None, 25, 25, 288)  0          ['mixed1[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 25, 25, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 25, 25, 64)   76800       ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 25, 25, 96)   82944       ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 25, 25, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 25, 25, 64)  192         ['conv2d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 25, 25, 64)  192         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 25, 25, 96)  288         ['conv2d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 25, 25, 64)  192         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " mixed2 (Concatenate)           (None, 25, 25, 288)  0           ['activation_19[0][0]',          \n",
            "                                                                  'activation_21[0][0]',          \n",
            "                                                                  'activation_24[0][0]',          \n",
            "                                                                  'activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 25, 25, 64)   18432       ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 25, 25, 64)  192         ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 25, 25, 96)   55296       ['activation_27[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 25, 25, 96)  288         ['conv2d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 12, 12, 384)  995328      ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 12, 12, 96)   82944       ['activation_28[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 12, 12, 384)  1152       ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 12, 12, 96)  288         ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 12, 12, 384)  0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 12, 12, 96)   0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_8 (MaxPooling2D)  (None, 12, 12, 288)  0          ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " mixed3 (Concatenate)           (None, 12, 12, 768)  0           ['activation_26[0][0]',          \n",
            "                                                                  'activation_29[0][0]',          \n",
            "                                                                  'max_pooling2d_8[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 12, 12, 128)  98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 12, 12, 128)  384        ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_34 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_34[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 12, 12, 128)  384        ['conv2d_41[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_35 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 12, 12, 128)  98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_35[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 12, 12, 128)  384        ['conv2d_37[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 12, 12, 128)  384        ['conv2d_42[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " activation_36 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_31[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_36[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 12, 12, 128)  384        ['conv2d_38[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 12, 12, 128)  384        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_32 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " activation_37 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_3 (AveragePo  (None, 12, 12, 768)  0          ['mixed3[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 12, 12, 192)  172032      ['activation_32[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 12, 12, 192)  172032      ['activation_37[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_3[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 12, 12, 192)  576        ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 12, 12, 192)  576        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 12, 12, 192)  576        ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 12, 12, 192)  576        ['conv2d_45[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " activation_33 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " activation_38 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " activation_39 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " mixed4 (Concatenate)           (None, 12, 12, 768)  0           ['activation_30[0][0]',          \n",
            "                                                                  'activation_33[0][0]',          \n",
            "                                                                  'activation_38[0][0]',          \n",
            "                                                                  'activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 12, 12, 160)  480        ['conv2d_50[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_44 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_44[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 12, 12, 160)  480        ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_45 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_45[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 12, 12, 160)  480        ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 12, 12, 160)  480        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_41 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " activation_46 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_41[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_46[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 12, 12, 160)  480        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 12, 12, 160)  480        ['conv2d_53[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_42 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " activation_47 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_4 (AveragePo  (None, 12, 12, 768)  0          ['mixed4[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_42[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_47[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_4[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 12, 12, 192)  576        ['conv2d_46[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 12, 12, 192)  576        ['conv2d_49[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 12, 12, 192)  576        ['conv2d_54[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 12, 12, 192)  576        ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_40 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " activation_43 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " activation_48 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " activation_49 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " mixed5 (Concatenate)           (None, 12, 12, 768)  0           ['activation_40[0][0]',          \n",
            "                                                                  'activation_43[0][0]',          \n",
            "                                                                  'activation_48[0][0]',          \n",
            "                                                                  'activation_49[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_55 (BatchN  (None, 12, 12, 160)  480        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_54 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_55[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_54[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_56 (BatchN  (None, 12, 12, 160)  480        ['conv2d_61[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_55 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_56[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_55[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 12, 12, 160)  480        ['conv2d_57[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_57 (BatchN  (None, 12, 12, 160)  480        ['conv2d_62[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_51 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_52[0][0]'] \n",
            "                                                                                                  \n",
            " activation_56 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_57[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_51[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_56[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_53 (BatchN  (None, 12, 12, 160)  480        ['conv2d_58[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_58 (BatchN  (None, 12, 12, 160)  480        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_52 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_53[0][0]'] \n",
            "                                                                                                  \n",
            " activation_57 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_58[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_5 (AveragePo  (None, 12, 12, 768)  0          ['mixed5[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_52[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_57[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_5[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 12, 12, 192)  576        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_54 (BatchN  (None, 12, 12, 192)  576        ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_59 (BatchN  (None, 12, 12, 192)  576        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_60 (BatchN  (None, 12, 12, 192)  576        ['conv2d_65[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_50 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " activation_53 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " activation_58 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_59[0][0]'] \n",
            "                                                                                                  \n",
            " activation_59 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " mixed6 (Concatenate)           (None, 12, 12, 768)  0           ['activation_50[0][0]',          \n",
            "                                                                  'activation_53[0][0]',          \n",
            "                                                                  'activation_58[0][0]',          \n",
            "                                                                  'activation_59[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_65 (BatchN  (None, 12, 12, 192)  576        ['conv2d_70[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_64 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_65[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_64[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_66 (BatchN  (None, 12, 12, 192)  576        ['conv2d_71[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_65 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_66[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_65[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_62 (BatchN  (None, 12, 12, 192)  576        ['conv2d_67[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_67 (BatchN  (None, 12, 12, 192)  576        ['conv2d_72[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_61 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_62[0][0]'] \n",
            "                                                                                                  \n",
            " activation_66 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_67[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_61[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_66[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_63 (BatchN  (None, 12, 12, 192)  576        ['conv2d_68[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_68 (BatchN  (None, 12, 12, 192)  576        ['conv2d_73[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_62 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_63[0][0]'] \n",
            "                                                                                                  \n",
            " activation_67 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_68[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_6 (AveragePo  (None, 12, 12, 768)  0          ['mixed6[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_62[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_74 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_67[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_75 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_6[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_61 (BatchN  (None, 12, 12, 192)  576        ['conv2d_66[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_64 (BatchN  (None, 12, 12, 192)  576        ['conv2d_69[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_69 (BatchN  (None, 12, 12, 192)  576        ['conv2d_74[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_70 (BatchN  (None, 12, 12, 192)  576        ['conv2d_75[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_60 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_61[0][0]'] \n",
            "                                                                                                  \n",
            " activation_63 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_64[0][0]'] \n",
            "                                                                                                  \n",
            " activation_68 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_69[0][0]'] \n",
            "                                                                                                  \n",
            " activation_69 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_70[0][0]'] \n",
            "                                                                                                  \n",
            " mixed7 (Concatenate)           (None, 12, 12, 768)  0           ['activation_60[0][0]',          \n",
            "                                                                  'activation_63[0][0]',          \n",
            "                                                                  'activation_68[0][0]',          \n",
            "                                                                  'activation_69[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_78 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_73 (BatchN  (None, 12, 12, 192)  576        ['conv2d_78[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_72 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_73[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_79 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_72[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_74 (BatchN  (None, 12, 12, 192)  576        ['conv2d_79[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_73 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_74[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_76 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_80 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_73[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_71 (BatchN  (None, 12, 12, 192)  576        ['conv2d_76[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_75 (BatchN  (None, 12, 12, 192)  576        ['conv2d_80[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_70 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_71[0][0]'] \n",
            "                                                                                                  \n",
            " activation_74 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_75[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_77 (Conv2D)             (None, 5, 5, 320)    552960      ['activation_70[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_81 (Conv2D)             (None, 5, 5, 192)    331776      ['activation_74[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_72 (BatchN  (None, 5, 5, 320)   960         ['conv2d_77[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_76 (BatchN  (None, 5, 5, 192)   576         ['conv2d_81[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_71 (Activation)     (None, 5, 5, 320)    0           ['batch_normalization_72[0][0]'] \n",
            "                                                                                                  \n",
            " activation_75 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_76[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_9 (MaxPooling2D)  (None, 5, 5, 768)   0           ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " mixed8 (Concatenate)           (None, 5, 5, 1280)   0           ['activation_71[0][0]',          \n",
            "                                                                  'activation_75[0][0]',          \n",
            "                                                                  'max_pooling2d_9[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_86 (Conv2D)             (None, 5, 5, 448)    573440      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_81 (BatchN  (None, 5, 5, 448)   1344        ['conv2d_86[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_80 (Activation)     (None, 5, 5, 448)    0           ['batch_normalization_81[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_83 (Conv2D)             (None, 5, 5, 384)    491520      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_87 (Conv2D)             (None, 5, 5, 384)    1548288     ['activation_80[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_78 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_83[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_82 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_87[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_77 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_78[0][0]'] \n",
            "                                                                                                  \n",
            " activation_81 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_82[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_84 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_77[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_85 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_77[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_88 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_81[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_89 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_81[0][0]']          \n",
            "                                                                                                  \n",
            " average_pooling2d_7 (AveragePo  (None, 5, 5, 1280)  0           ['mixed8[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_82 (Conv2D)             (None, 5, 5, 320)    409600      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_79 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_84[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_80 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_85[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_83 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_88[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_84 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_89[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_90 (Conv2D)             (None, 5, 5, 192)    245760      ['average_pooling2d_7[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_77 (BatchN  (None, 5, 5, 320)   960         ['conv2d_82[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_78 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_79[0][0]'] \n",
            "                                                                                                  \n",
            " activation_79 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_80[0][0]'] \n",
            "                                                                                                  \n",
            " activation_82 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_83[0][0]'] \n",
            "                                                                                                  \n",
            " activation_83 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_84[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_85 (BatchN  (None, 5, 5, 192)   576         ['conv2d_90[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_76 (Activation)     (None, 5, 5, 320)    0           ['batch_normalization_77[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9_0 (Concatenate)         (None, 5, 5, 768)    0           ['activation_78[0][0]',          \n",
            "                                                                  'activation_79[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 5, 5, 768)    0           ['activation_82[0][0]',          \n",
            "                                                                  'activation_83[0][0]']          \n",
            "                                                                                                  \n",
            " activation_84 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_85[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9 (Concatenate)           (None, 5, 5, 2048)   0           ['activation_76[0][0]',          \n",
            "                                                                  'mixed9_0[0][0]',               \n",
            "                                                                  'concatenate[0][0]',            \n",
            "                                                                  'activation_84[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_95 (Conv2D)             (None, 5, 5, 448)    917504      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_90 (BatchN  (None, 5, 5, 448)   1344        ['conv2d_95[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_89 (Activation)     (None, 5, 5, 448)    0           ['batch_normalization_90[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_92 (Conv2D)             (None, 5, 5, 384)    786432      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_96 (Conv2D)             (None, 5, 5, 384)    1548288     ['activation_89[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_87 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_92[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_91 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_96[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_86 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_87[0][0]'] \n",
            "                                                                                                  \n",
            " activation_90 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_91[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_93 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_86[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_94 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_86[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_97 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_90[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_98 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_90[0][0]']          \n",
            "                                                                                                  \n",
            " average_pooling2d_8 (AveragePo  (None, 5, 5, 2048)  0           ['mixed9[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_91 (Conv2D)             (None, 5, 5, 320)    655360      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_88 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_93[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_89 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_94[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_92 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_97[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_93 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_98[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_99 (Conv2D)             (None, 5, 5, 192)    393216      ['average_pooling2d_8[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_86 (BatchN  (None, 5, 5, 320)   960         ['conv2d_91[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_87 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_88[0][0]'] \n",
            "                                                                                                  \n",
            " activation_88 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_89[0][0]'] \n",
            "                                                                                                  \n",
            " activation_91 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_92[0][0]'] \n",
            "                                                                                                  \n",
            " activation_92 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_93[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_94 (BatchN  (None, 5, 5, 192)   576         ['conv2d_99[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_85 (Activation)     (None, 5, 5, 320)    0           ['batch_normalization_86[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9_1 (Concatenate)         (None, 5, 5, 768)    0           ['activation_87[0][0]',          \n",
            "                                                                  'activation_88[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 5, 5, 768)    0           ['activation_91[0][0]',          \n",
            "                                                                  'activation_92[0][0]']          \n",
            "                                                                                                  \n",
            " activation_93 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_94[0][0]'] \n",
            "                                                                                                  \n",
            " mixed10 (Concatenate)          (None, 5, 5, 2048)   0           ['activation_85[0][0]',          \n",
            "                                                                  'mixed9_1[0][0]',               \n",
            "                                                                  'concatenate_1[0][0]',          \n",
            "                                                                  'activation_93[0][0]']          \n",
            "                                                                                                  \n",
            " flatten_3 (Flatten)            (None, 51200)        0           ['mixed10[0][0]']                \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 10)           512010      ['flatten_3[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 22,314,794\n",
            "Trainable params: 512,010\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "inception_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qG_9vNEDcUW5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdb90a2f-91f5-47cf-82d6-62474da64477"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-54-361267ce6862>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  transfer_inception=inception_model.fit_generator(training_set,validation_data=validation_generator,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "459/459 [==============================] - 298s 559ms/step - loss: 2.7762 - accuracy: 0.6888 - val_loss: 2.4999 - val_accuracy: 0.7210\n",
            "Epoch 2/50\n",
            "459/459 [==============================] - 247s 538ms/step - loss: 1.5254 - accuracy: 0.8260 - val_loss: 2.3065 - val_accuracy: 0.7707\n",
            "Epoch 3/50\n",
            "459/459 [==============================] - 245s 534ms/step - loss: 1.3138 - accuracy: 0.8602 - val_loss: 2.1676 - val_accuracy: 0.8056\n",
            "Epoch 4/50\n",
            "459/459 [==============================] - 242s 528ms/step - loss: 1.0814 - accuracy: 0.8898 - val_loss: 3.4802 - val_accuracy: 0.7581\n",
            "Epoch 5/50\n",
            "429/459 [===========================>..] - ETA: 13s - loss: 1.2631 - accuracy: 0.8870"
          ]
        }
      ],
      "source": [
        "transfer_inception=inception_model.fit_generator(training_set,validation_data=validation_generator,\n",
        "                                                 validation_steps=len(validation_generator),steps_per_epoch=len(training_set),epochs=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMsu4KhJcdsM"
      },
      "source": [
        "After training the model I have noticed that the model is **Overfiiting.**\n",
        "\n",
        "**Overfitting means for training dataset the model perform good but for test dataset the model will not perform well.**  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPL4GyZUAKbc"
      },
      "outputs": [],
      "source": [
        "# Scores is just a list containing loss and accuracy value\n",
        "scores=inception_model.evaluate(training_set)\n",
        "scores2=inception_model.evaluate(test_set)\n",
        "print(\"Training Loss is :\"+str(scores[0]))\n",
        "print(\"Training Accuracy is :\"+str(scores[1]*100)+\" %\")\n",
        "print(\"Testing Loss is : \"+str(scores2[0]))\n",
        "print(\"Testing Accuracy is : \"+str(scores2[1]*100)+\" %\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpSLB3DVBQcF"
      },
      "outputs": [],
      "source": [
        "test_steps_per_epoch = np.math.ceil(test_set.samples / test_set.batch_size)\n",
        "predictions = inception_model.predict(test_set, steps=test_steps_per_epoch)\n",
        "\n",
        "# Get most likely class\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Get true classes and class Labels\n",
        "true_classes = test_set.classes\n",
        "class_labels = list(test_set.class_indices.keys())   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_hiN2MlBVUv"
      },
      "outputs": [],
      "source": [
        "#Classification Report\n",
        "import sklearn.metrics as metrics\n",
        "report = metrics.classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
        "print(report) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6Y8WiMiBaHV"
      },
      "outputs": [],
      "source": [
        "#Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "sns.heatmap(confusion_matrix(true_classes,predicted_classes),annot=True,fmt='.5g') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUUvEHYWcXsZ"
      },
      "outputs": [],
      "source": [
        "# plot the loss\n",
        "plt.plot(transfer_inception.history['loss'], label='train loss')\n",
        "plt.plot(transfer_inception.history['val_loss'], label='val loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('LossVal_loss')\n",
        "\n",
        "# plot the accuracy\n",
        "plt.plot(transfer_inception.history['accuracy'], label='train acc')\n",
        "plt.plot(transfer_inception.history['val_accuracy'], label='val acc')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('AccVal_acc')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbvZiC-6cmyh"
      },
      "source": [
        "#### Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGdh89j9cxiy"
      },
      "outputs": [],
      "source": [
        "y_pred_incep=inception_model.predict(test_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6QO7M3hc2pX"
      },
      "source": [
        "**The predicted output is a probability due to the activation funtion Softmax, it returns probability of the classes\n",
        "We will now change the probability to discrete values**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u43JkG-bcztG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "y_pred_incep=np.argmax(y_pred_incep,axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVjR0wjwc7E1"
      },
      "source": [
        "**Saving the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7Kw6x6Lc57i"
      },
      "outputs": [],
      "source": [
        "inception_model.save(\"Tomato_inceptionv3.h5\")\n",
        "from tensorflow.keras.models import load_model\n",
        "modelinception=load_model(\"Tomato_inceptionv3.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znmkuzP8dTag"
      },
      "source": [
        "**Testing the Model with validation dataset** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbR1OXcRdQIr"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# for fn in uploaded.keys():\n",
        "#   # predict images\n",
        "#   path = '/content/' + fn\n",
        "#   img = image.load_img(path, target_size=(224,224))\n",
        "#   x = image.img_to_array(img)\n",
        "#   x = np.expand_dims(x, axis =0)\n",
        "\n",
        "#   preds = modelinception.predict(x)\n",
        "#   preds=np.argmax(preds, axis=1)\n",
        "#   if preds==0:\n",
        "#         preds=\"Tomato___Bacterial_spot\"\n",
        "#   elif preds==1:\n",
        "#         preds=\"Tomato___Early_blight\"\n",
        "#   elif preds==2:\n",
        "#         preds=\"Tomato___healthy\"\n",
        "#   elif preds==3:\n",
        "#         preds=\"Tomato___Late_blight\"\n",
        "#   elif preds==4:\n",
        "#         preds=\"Tomato___Leaf_Mold\"\n",
        "#   elif preds==5:\n",
        "#         preds=\"Tomato___Septoria_leaf_spot\"\n",
        "#   elif preds==6:\n",
        "#         preds=\"Tomato___Spider_mites Two-spotted_spider_mite\"\n",
        "#   elif preds==7:\n",
        "#         preds=\"Tomato___Target_Spot\"\n",
        "#   elif preds==8:\n",
        "#         preds=\"Tomato___Tomato_mosaic_virus\"\n",
        "#   else:\n",
        "#         preds=\"Tomato___Tomato_Yellow_Leaf_Curl_Virus\"\n",
        "#   print(preds)\n",
        "#   plt.imshow(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6pwgxTCeJI4"
      },
      "source": [
        "### VGG16\n",
        "\n",
        "VGG16 is a convolutional neural network model proposed by K. Simonyan and A. Zisserman from the University of Oxford in the paper Very Deep Convolutional Networks for Large-Scale Image Recognition. The model achieves 92.7% top-5 test accuracy in ImageNet, which is a dataset of over 14 million images belonging to 1000 classes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FlQy84KIhVtp"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras \n",
        "from tensorflow.keras.layers import Dense,Flatten\n",
        "from tensorflow.keras.models import Model, Sequential,load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxdDg_fv4gJp"
      },
      "outputs": [],
      "source": [
        "TRAINING_DIR = '/content/drive/MyDrive/BTP/Dataset/dataset/New Plant Diseases Dataset(Augmented)/train/' \n",
        "TESTING_DIR = '/content/drive/MyDrive/BTP/Dataset/dataset/New Plant Diseases Dataset(Augmented)/valid/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GS52YX5wgZe9"
      },
      "outputs": [],
      "source": [
        "train_datagen=ImageDataGenerator(validation_split=0.2,rescale=1./255,\n",
        "                                 horizontal_flip=True,shear_range=.2,rotation_range=.2)\n",
        "test_datagen=ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "training_set=train_datagen.flow_from_directory(TRAINING_DIR,\n",
        "                                               target_size=(224,224),class_mode=\"categorical\",batch_size=50,shuffle=True,subset=\"training\")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "        TRAINING_DIR,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical',\n",
        "        shuffle=True,\n",
        "        subset=\"validation\")\n",
        "\n",
        "test_set=test_datagen.flow_from_directory(TESTING_DIR,\n",
        "                                          target_size=(224,224),batch_size=50,class_mode=\"categorical\",shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HW2SjSoreYG4"
      },
      "outputs": [],
      "source": [
        "vgg16=VGG16(include_top=False,weights=\"imagenet\",input_shape=[224,224,3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOBcORk5eacd"
      },
      "source": [
        "**We will not train the layers because the layers of VGG16 layers are already trained with imagenet dataset.** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84jretNSeYkt"
      },
      "outputs": [],
      "source": [
        "for layer in vgg16.layers:\n",
        "  layer.trainable=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGNFXTK1ejJl"
      },
      "outputs": [],
      "source": [
        "folder=glob(\"/content/drive/MyDrive/BTP/Dataset/dataset/New Plant Diseases Dataset(Augmented)/train/*\")\n",
        "folder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEBhR0pNevVB"
      },
      "source": [
        "**Adding a flatten layer along with a Dense layer whose neuron will be equal to the number of classes with and activation funtion softmax**\n",
        "\n",
        "**Then we will concat the model and name vgg16_model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56oSxIc4ewYI"
      },
      "outputs": [],
      "source": [
        "x=Flatten()(vgg16.output)\n",
        "pred_vgg16=Dense(units=len(folder),activation=\"softmax\")(x)\n",
        "vgg16_model=Model(inputs=vgg16.input,outputs=pred_vgg16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyOY069ie3cH"
      },
      "source": [
        "**We have taken the optimizer Adam and the loss will be categorical crossentropy and our aim will be to find the accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqDz8PfXeyr8"
      },
      "outputs": [],
      "source": [
        "vgg16_model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BroOCbkfHDc"
      },
      "source": [
        "#### Final Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNGGyH4sfEF1"
      },
      "outputs": [],
      "source": [
        "vgg16_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tofsceQ2fOAA"
      },
      "source": [
        "**Train the model with an epoch of 20 and the validation data will be the test data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nr2Om-QefLVi"
      },
      "outputs": [],
      "source": [
        "transfer_vgg16=vgg16_model.fit_generator(training_set,validation_data=validation_generator,epochs=50,\n",
        "                                         validation_steps=len(validation_generator),steps_per_epoch=len(training_set))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suJfNqEPfVpu"
      },
      "source": [
        "After the training I have noticed that the model is not **overfit and the loss and accuracy is somewhat equal to validation loss and validation accuracy.**\n",
        "\n",
        "Which means the model will perform good"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07e9TFYrBm2B"
      },
      "outputs": [],
      "source": [
        "# Scores is just a list containing loss and accuracy value\n",
        "scores=vgg16_model.evaluate(training_set)\n",
        "scores2=vgg16_model.evaluate(test_set)\n",
        "print(\"Training Loss is :\"+str(scores[0]))\n",
        "print(\"Training Accuracy is :\"+str(scores[1]*100)+\" %\")\n",
        "print(\"Testing Loss is : \"+str(scores2[0]))\n",
        "print(\"Testing Accuracy is : \"+str(scores2[1]*100)+\" %\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wlDNlu8Bvoy"
      },
      "outputs": [],
      "source": [
        "test_steps_per_epoch = np.math.ceil(test_set.samples / test_set.batch_size)\n",
        "predictions = vgg16_model.predict(test_set, steps=test_steps_per_epoch)\n",
        "\n",
        "# Get most likely class\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Get true classes and class Labels\n",
        "true_classes = test_set.classes\n",
        "class_labels = list(test_set.class_indices.keys())   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAmhW9jfB0ou"
      },
      "outputs": [],
      "source": [
        "#Classification Report\n",
        "import sklearn.metrics as metrics\n",
        "report = metrics.classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
        "print(report) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdCeC_UVB2Rm"
      },
      "outputs": [],
      "source": [
        "#Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "sns.heatmap(confusion_matrix(true_classes,predicted_classes),annot=True,fmt='.5g') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dihpv1CmfU1R"
      },
      "outputs": [],
      "source": [
        "# plot the loss\n",
        "plt.plot(transfer_vgg16.history['loss'], label='train loss')\n",
        "plt.plot(transfer_vgg16.history['val_loss'], label='val loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('LossVal_loss')\n",
        "\n",
        "# plot the accuracy\n",
        "plt.plot(transfer_vgg16.history['accuracy'], label='train acc')\n",
        "plt.plot(transfer_vgg16.history['val_accuracy'], label='val acc')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('AccVal_acc')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUQn2ez7fagb"
      },
      "source": [
        "#### Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u61kMqKjfYOg"
      },
      "outputs": [],
      "source": [
        "y_pred_vgg16=vgg16_model.predict(test_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_UlqUXRfgnL"
      },
      "source": [
        "**The predicted output is a probability due to the activation funtion Softmax, it returns probability of the classes\n",
        "We will now change the probability to discrete values**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4TenMDiuff_6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "y_pred_vgg16=np.argmax(y_pred_vgg16,axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfDUk7TZfk7F"
      },
      "source": [
        "**Saving the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcXXGBnpfkNx"
      },
      "outputs": [],
      "source": [
        "vgg16_model.save(\"Tomato_vgg16.h5\")\n",
        "from tensorflow.keras.models import load_model\n",
        "modelvgg16=load_model(\"Tomato_vgg16.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxKUfESRfs2J"
      },
      "source": [
        "**Testing the Model with validation dataset** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3wGsW4nYfpuK"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# for fn in uploaded.keys():\n",
        "#   # predict images\n",
        "#   path = '/content/' + fn\n",
        "#   img = image.load_img(path, target_size=(224,224))\n",
        "#   x = image.img_to_array(img)\n",
        "#   x = np.expand_dims(x, axis =0)\n",
        "\n",
        "#   preds = modelvgg16.predict(x)\n",
        "#   preds=np.argmax(preds, axis=1)\n",
        "#   if preds==0:\n",
        "#         preds=\"Tomato___Bacterial_spot\"\n",
        "#   elif preds==1:\n",
        "#         preds=\"Tomato___Early_blight\"\n",
        "#   elif preds==2:\n",
        "#         preds=\"Tomato___healthy\"\n",
        "#   elif preds==3:\n",
        "#         preds=\"Tomato___Late_blight\"\n",
        "#   elif preds==4:\n",
        "#         preds=\"Tomato___Leaf_Mold\"\n",
        "#   elif preds==5:\n",
        "#         preds=\"Tomato___Septoria_leaf_spot\"\n",
        "#   elif preds==6:\n",
        "#         preds=\"Tomato___Spider_mites Two-spotted_spider_mite\"\n",
        "#   elif preds==7:\n",
        "#         preds=\"Tomato___Target_Spot\"\n",
        "#   elif preds==8:\n",
        "#         preds=\"Tomato___Tomato_mosaic_virus\"\n",
        "#   else:\n",
        "#         preds=\"Tomato___Tomato_Yellow_Leaf_Curl_Virus\"\n",
        "#   print(preds)\n",
        "#   plt.imshow(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO_1Qp1baahI"
      },
      "source": [
        "# Misc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyggnvy5AR0k"
      },
      "outputs": [],
      "source": [
        "# fit the model, it will take some time to execute\n",
        "r = model.fit_generator(\n",
        "  training_set,\n",
        "  validation_data=test_set,\n",
        "  epochs=30,\n",
        "  steps_per_epoch=len(training_set),\n",
        "  validation_steps=len(test_set)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cBbaJvgDGBl"
      },
      "outputs": [],
      "source": [
        "# Scores is just a list containing loss and accuracy value\n",
        "scores=r.evaluate(train_generator)\n",
        "scores2=r.evaluate(test_generator)\n",
        "print(\"Training Loss is :\"+str(scores[0]))\n",
        "print(\"Training Accuracy is :\"+str(scores[1]*100)+\" %\")\n",
        "print(\"Testing Loss is :\"+str(scores2[0]))\n",
        "print(\"Testing Accuracy is :\"+str(scores2[1]*100)+\" %\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnUPy5FcDLEZ"
      },
      "outputs": [],
      "source": [
        "test_steps_per_epoch = np.math.ceil(test_generator.samples / test_generator.batch_size)\n",
        "predictions = r.predict(test_generator, steps=test_steps_per_epoch)\n",
        "\n",
        "# Get most likely class\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Get true classes and class Labels\n",
        "true_classes = test_generator.classes\n",
        "class_labels = list(test_generator.class_indices.keys())   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGGcMpEZDRBM"
      },
      "outputs": [],
      "source": [
        "#Classification Report\n",
        "import sklearn.metrics as metrics\n",
        "report = metrics.classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
        "print(report) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMxXVhvDDXJq"
      },
      "outputs": [],
      "source": [
        "#Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "sns.heatmap(confusion_matrix(true_classes,predicted_classes),annot=True,fmt='.5g') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9NY1W2kATBT"
      },
      "outputs": [],
      "source": [
        "# Plot the Loss and Accuracy\n",
        "# Loss\n",
        "plt.plot(r.history['loss'], label='train loss')\n",
        "plt.plot(r.history['val_loss'], label='val loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('LossVal_loss')\n",
        "\n",
        "# Accuracy\n",
        "plt.plot(r.history['accuracy'], label='train acc')\n",
        "plt.plot(r.history['val_accuracy'], label='val acc')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('AccVal_acc')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "W0KbT9jWoucE",
        "AUQn2ez7fagb",
        "sO_1Qp1baahI"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.8 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "b2a8588e3ad7e07cfdec7f9a787e4a6b265ca4cc403aa707d971eb4fd1ad0edc"
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}